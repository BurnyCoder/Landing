## Tags
- Metadata: #topic 
- Part of: [[OpenAI]] [[DeepMind]] [[Anthropic]] [[Artificial intelligence safety]]
- Related: 
- Includes:
- Additional: 
## Significance
- 
## Intuitive summaries
- 
## Definitions
- Form of evaluation that elicits model vulnerabilities that might lead to undesirable behaviors. The goal of red-teaming [[Language model|language models]] is to craft a prompt that would trigger the model to generate text that is likely to cause harm
## Technical summaries
-  
## Main resources 
- [Red-Teaming Large Language Models](https://huggingface.co/blog/red-teaming)
	- <iframe src="https://huggingface.co/blog/red-teaming" allow="fullscreen" allowfullscreen="" style="height:100%;width:100%; aspect-ratio: 16 / 5; "></iframe>
## Landscapes
- 
## Contents
- 
## Deep dives
- 
## Brain storming
- 
## Additional resources  
- 
## Related
- 
## Related resources  
- 
## AI 
- 
## Additional metadata 
-  #processed #processing #toprocess #important #short #long #casual #focus
- Unfinished: #metadata #tags