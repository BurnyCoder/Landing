## Tags
- Metadata: #topic 
- Part of:
- Related: 
- Includes:
- Additional: 
## Significance
- 
## Intuitive summaries
- 
## Definitions
- 
## Technical summaries
-  
## Main resources 
- 
	- <iframe src="https://en.wikipedia.org/wiki/AI_safety" allow="fullscreen" allowfullscreen="" style="height:100%;width:100%; aspect-ratio: 16 / 5; "></iframe>
## Landscapes
- [Alex Turner’s landscape](https://www.youtube.com/watch?v=02kbWY5mahQ)
	- ![US presidents rate AI alignment agendas - YouTube](https://www.youtube.com/watch?v=02kbWY5mahQ)
		- [[Mechanistic interpretability]] -  taking a trained [[artificial neural network]], and analyzing the weights to reverse engineer the algorithms learned by the model.
		- [[Agent foundations]] - [Artificial Intelligence @ MIRI](https://intelligence.org/)
		- [[Cognitive Emulation]] - build predictably _boundable_ systems
		- [[Shard Theory]] - research program aimed at explaining the systematic relationships between the reinforcement schedules and learned values of reinforcement-learning agents
		- [[Infrabayesianism]] - [Infra-Bayesianism - LessWrong](https://www.lesswrong.com/s/CmrW8fCmSLK7E25sa)
		- [[Eliciting latent knowledge]] -  How can we train this model to report its latent knowledge of off-screen events? [Eliciting latent knowledge. How can we train an AI to honestly tell… | by Paul Christiano | AI Alignment](https://ai-alignment.com/eliciting-latent-knowledge-f977478608fc)
	
## Contents
- 
## Deep dives
- 
## Brain storming
- 
## Additional resources  
- 
## Related
- 
## Related resources  
- 
## AI 
- 
## Additional metadata 
-  #processed #processing #toprocess #important #short #long #casual #focus
- Unfinished: #metadata #tags