## Tags
- Metadata: #topic 
- Part of: [[Artificial Intelligence]] [[Machine learning]] [[Risks of artificial intelligence]] [[Risks]]
- Related: 
- Includes:
- Additional: 
## Significance
- 
## Intuitive summaries
- 
## Definitions
- 
## Technical summaries
-  
## Main resources 
- 
	- <iframe src="https://en.wikipedia.org/wiki/AI_safety" allow="fullscreen" allowfullscreen="" style="height:100%;width:100%; aspect-ratio: 16 / 5; "></iframe>
## Landscapes
- Methods
	- [[Mechanistic interpretability]] 
		 -  ![[Mechanistic interpretability#Definitions]]
	- [[Readteaming]] - form of evaluation that elicits model vulnerabilities that might lead to undesirable behaviors,  goal of red-teaming language models is to craft a prompt that would trigger the model to generate text that is likely to cause harm
	- 
- [Alex Turner’s landscape](https://www.youtube.com/watch?v=02kbWY5mahQ)
	- ![US presidents rate AI alignment agendas - YouTube](https://www.youtube.com/watch?v=02kbWY5mahQ)
		- [[Mechanistic interpretability]]
			- ![[Mechanistic interpretability#Definitions]]
		- [[Agent foundations]] - [Artificial Intelligence @ MIRI](https://intelligence.org/)
		- [[Cognitive Emulation]] - build predictably _boundable_ systems
		- [[Shard Theory]] - research program aimed at explaining the systematic relationships between the reinforcement schedules and learned values of reinforcement-learning agents
		- [[Infrabayesianism]] - [Infra-Bayesianism - LessWrong](https://www.lesswrong.com/s/CmrW8fCmSLK7E25sa)
		- [[Eliciting latent knowledge]] -  How can we train this model to report its latent knowledge of off-screen events? [Eliciting latent knowledge. How can we train an AI to honestly tell… | by Paul Christiano | AI Alignment](https://ai-alignment.com/eliciting-latent-knowledge-f977478608fc)
	
## Contents
- 
## Deep dives
- 
## Brain storming
- 
## Additional resources  
- 
## Related
- 
## Related resources  
- 
## AI 
- 
## Additional metadata 
-  #processed #processing #toprocess #important #short #long #casual #focus
- Unfinished: #metadata #tags