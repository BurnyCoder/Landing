## Tags
- Metadata: #topic 
- Part of: [[Artificial Intelligence]] [[Science]] [[Engineering]] [[Science]] [[Technology]]
- Related: 
- Includes:
- Additional: 
## Significance
- 
## Intuitive summaries
- 
## Definitions
- A branch of [[artificial Intelligence]] that focuses on [[Statistics|statistical]] [[Algorithm|algorithms]] that can effectively generalize and thus perform tasks without explicit instructions.
## Technical summaries
-  
## Main resources 
- [Machine learning - Wikipedia](https://en.wikipedia.org/wiki/Machine_learning)
<iframe src="https://en.wikipedia.org/wiki/Machine_learning" allow="fullscreen" allowfullscreen="" style="height:100%;width:100%; aspect-ratio: 16 / 5; "></iframe>
## Landscapes
- [Outline of machine learning - Wikipedia](https://en.wikipedia.org/wiki/Outline_of_machine_learning)
<iframe src="https://en.wikipedia.org/wiki/Outline_of_machine_learning" allow="fullscreen" allowfullscreen="" style="height:100%;width:100%; aspect-ratio: 16 / 5; "></iframe>
	- By methods
		- [[Instance-based algorithm]]
		- [[Regression analysis]]
		- [[Dimensionality reduction]]
		- [[Ensemble learning]]
		- [[Meta learning]]
		- [[Reinforcement learning]]
		- [[Supervised learning]]
			- [[Bayesian statistics]]
			- [[Decision tree algorithm]]
			- [[Classifier]]
				- [[Support-vector machines]]
		- [[Unsupervised learning]]
			- [[Artificial neural network]]
			- [[Association rule learning]]
			- [[Hiearchical clustering]]
			- [[Cluster analysis]]
			- [[Anomaly detection]]
		- [[Semi-supervised learning]]
		- [[Deep learning]]
	- By application
		- [[Automating science]]
		- [[Data mining]]
		- [[Computer vision]]
		- [[Classification]]
		- [[Bioinformatics]]
		- [[Natural language processing]]
			- [[Large language model]]
				- [[Transformer]]
			- [[Large multimodal model]]
		- [[Pattern recognition]]
		- [[Recommendation system]]
		- [[Search engine]]
		- [[Social engineering]]
	- [Machine learning Applications - Wikipedia](https://en.wikipedia.org/wiki/Machine_learning#Applications
	- Machine learning algorithms
		- [[Gradient descent]]
- [[Connectionist artificial intelligence]]
	- ![[Connectionist artificial intelligence#Definitions]]
- [[Hybrid artificial intelligence]]  
- [[Generative artificial intelligence]]
- [[Quantum machine learning]]
- [[Thermodynamic AI]]
- [[Mechanistic interpretability]]
- [[Mathematical theory of artificial intelligence]]
- [[Meta-learning]]
- [[Online machine learning]]
- [The landscape of the Machine Learning section of ArXiv.](https://twitter.com/leland_mcinnes/status/1731752287788265726)
	- [[landing/docs/Images/d53207aee25be09f22c9bebc583ac099_MD5.jpeg|Open: Pasted image 20231204230523.png]]
![[landing/docs/Images/d53207aee25be09f22c9bebc583ac099_MD5.jpeg]]
## Lists of resouces

[GitHub - patrickloeber/ml-study-plan: The Ultimate FREE Machine Learning Study Plan](https://github.com/patrickloeber/ml-study-plan)
[GitHub - dair-ai/ML-YouTube-Courses: ðŸ“º Discover the latest machine learning / AI courses on YouTube.](https://github.com/dair-ai/ML-YouTube-Courses)
[GitHub - yazdotai/machine-learning-video-courses: Comprehensive list of machine learning videos](https://github.com/yazdotai/machine-learning-video-courses)
[GitHub - mirerfangheibi/Machine-Learning-Resources: Free and High-Quality Materials to Study Deep Learning](https://github.com/mirerfangheibi/Machine-Learning-Resources)
[ML Resources](https://sgfin.github.io/learning-resources/#ml)
[GitHub - therealsreehari/Learn-Data-Science-For-Free: This repositary is a combination of different resources lying scattered all over the internet. The reason for making such an repositary is to combine all the valuable resources in a sequential manner, so that it helps every beginners who are in a search of free and structured learning resource for Data Science. For Constant Updates Follow me in Twitter.](https://github.com/therealsreehari/Learn-Data-Science-For-Free)
[GitHub - openlists/MathStatsResources](https://github.com/openlists/MathStatsResources)
[GitHub - mdozmorov/Statistics_notes: Statistics, data analysis tutorials and learning resources](https://github.com/mdozmorov/Statistics_notes)
[GitHub - Machine-Learning-Tokyo/AI_Curriculum: Open Deep Learning and Reinforcement Learning lectures from top Universities like Stanford, MIT, UC Berkeley.](https://github.com/Machine-Learning-Tokyo/AI_Curriculum)
[GitHub - bentrevett/machine-learning-courses: A collection of machine learning courses.](https://github.com/bentrevett/machine-learning-courses)
[GitHub - Developer-Y/cs-video-courses: List of Computer Science courses with video lectures.](https://github.com/Developer-Y/cs-video-courses?tab=readme-ov-file#artificial-intelligence)
[GitHub - tigerneil/awesome-deep-rl: For deep RL and the future of AI.](https://github.com/tigerneil/awesome-deep-rl)
[GitHub - Developer-Y/math-science-video-lectures: List of Science courses with video lectures](https://github.com/Developer-Y/math-science-video-lectures)
[GitHub - Machine-Learning-Tokyo/Math_resources](https://github.com/Machine-Learning-Tokyo/Math_resources)
[GitHub - dair-ai/Mathematics-for-ML: ðŸ§®  A collection of resources to learn mathematics for machine learning](https://github.com/dair-ai/Mathematics-for-ML)
[Foundations of Machine Learning](https://bloomberg.github.io/foml/#lectures)
[Data Science and Machine Learning Resources â€” Jon Krohn](https://www.jonkrohn.com/resources)
https://www.kdnuggets.com/10-github-repositories-to-master-machine-learning
[GitHub - exajobs/university-courses-collection: A collection of awesome CS courses, assignments, lectures, notes, readings & examinations available online for free.](https://github.com/exajobs/university-courses-collection?tab=readme-ov-file#artificial-intelligence)
[GitHub - prakhar1989/awesome-courses: :books: List of awesome university courses for learning Computer Science!](https://github.com/prakhar1989/awesome-courses?tab=readme-ov-file#artificial-intelligence)
[GitHub - owainlewis/awesome-artificial-intelligence: A curated list of Artificial Intelligence (AI) courses, books, video lectures and papers.](https://github.com/owainlewis/awesome-artificial-intelligence)
[GitHub - josephmisiti/awesome-machine-learning: A curated list of awesome Machine Learning frameworks, libraries and software.](https://github.com/josephmisiti/awesome-machine-learning)
[GitHub - academic/awesome-datascience: :memo: An awesome Data Science repository to learn and apply for real world problems.](https://github.com/academic/awesome-datascience?tab=readme-ov-file#the-data-science-toolbox)
[GitHub - ChristosChristofidis/awesome-deep-learning: A curated list of awesome Deep Learning tutorials, projects and communities.](https://github.com/ChristosChristofidis/awesome-deep-learning)
[GitHub - guillaume-chevalier/Awesome-Deep-Learning-Resources: Rough list of my favorite deep learning resources, useful for revisiting topics or for reference. I have got through all of the content listed there, carefully. - Guillaume Chevalier](https://github.com/guillaume-chevalier/Awesome-Deep-Learning-Resources?tab=readme-ov-file#online-classes)
[GitHub - MartinuzziFrancesco/awesome-scientific-machine-learning: A curated list of awesome Scientific Machine Learning (SciML) papers, resources and software](https://github.com/MartinuzziFrancesco/awesome-scientific-machine-learning)
[GitHub - SE-ML/awesome-seml: A curated list of articles that cover the software engineering best practices for building machine learning applications.](https://github.com/SE-ML/awesome-seml)
[GitHub - jtoy/awesome-tensorflow: TensorFlow - A curated list of dedicated resources http://tensorflow.org](https://github.com/jtoy/awesome-tensorflow)
[GitHub - altamiracorp/awesome-xai: Awesome Explainable AI (XAI) and Interpretable ML Papers and Resources](https://github.com/altamiracorp/awesome-xai)
[GitHub - ujjwalkarn/Machine-Learning-Tutorials: machine learning and deep learning tutorials, articles and other resources](https://github.com/ujjwalkarn/Machine-Learning-Tutorials)
[GitHub - kiloreux/awesome-robotics: A list of awesome Robotics resources](https://github.com/kiloreux/awesome-robotics)
[GitHub - jbhuang0604/awesome-computer-vision: A curated list of awesome computer vision resources](https://github.com/jbhuang0604/awesome-computer-vision)
[GitHub - dk-liang/Awesome-Visual-Transformer: Collect some papers about transformer with vision. Awesome Transformer with Computer Vision (CV)](https://github.com/dk-liang/Awesome-Visual-Transformer)
[GitHub - ChanganVR/awesome-embodied-vision: Reading list for research topics in embodied vision](https://github.com/ChanganVR/awesome-embodied-vision)
[GitHub - EthicalML/awesome-production-machine-learning: A curated list of awesome open source libraries to deploy, monitor, version and scale your machine learning](https://github.com/EthicalML/awesome-production-machine-learning)
[GitHub - wangyongjie-ntu/Awesome-explainable-AI: A  collection of research materials on explainable AI/ML](https://github.com/wangyongjie-ntu/Awesome-explainable-AI)
[GitHub - jphall663/awesome-machine-learning-interpretability: A curated list of awesome responsible machine learning resources.](https://github.com/jphall663/awesome-machine-learning-interpretability)
[GitHub - JShollaj/awesome-llm-interpretability: A curated list of Large Language Model (LLM) Interpretability resources.](https://github.com/JShollaj/awesome-llm-interpretability)
[GitHub - MinghuiChen43/awesome-deep-phenomena: A curated list of papers of interesting empirical study and insight on deep learning. Continually updating...](https://github.com/MinghuiChen43/awesome-deep-phenomena)
[GitHub - Nikasa1889/awesome-deep-learning-theory: A curated list of awesome Deep Learning theories that shed light on the mysteries of DL](https://github.com/Nikasa1889/awesome-deep-learning-theory)
[[2106.10165] The Principles of Deep Learning Theory](https://arxiv.org/abs/2106.10165)
[GitHub - awesomedata/awesome-public-datasets: A topic-centric list of HQ open datasets.](https://github.com/awesomedata/awesome-public-datasets)
[GitHub - jsbroks/awesome-dataset-tools: ðŸ”§ A curated list of awesome dataset tools](https://github.com/jsbroks/awesome-dataset-tools)
[GitHub - mint-lab/awesome-robotics-datasets: A collection of useful datasets for robotics and computer vision](https://github.com/mint-lab/awesome-robotics-datasets)
[GitHub - kelvins/awesome-mlops: :sunglasses: A curated list of awesome MLOps tools](https://github.com/kelvins/awesome-mlops)
[GitHub - Bisonai/awesome-edge-machine-learning: A curated list of awesome edge machine learning resources, including research papers, inference engines, challenges, books, meetups and others.](https://github.com/Bisonai/awesome-edge-machine-learning)
## Contents
- 
## Crossovers
![[Artificial Intelligence#Crossovers]]
## Deep dives
- [[Theory of Everything in Intelligence]]
	-  ![[Theory of Everything in Intelligence#Definitions]]
## Brain storming
- 
## Additional resources  
- 
## Related
- 
## Explanation by AI 
- 
## Landscapes by AI 
- Machine Learning Algorithms
â”‚
â”œâ”€ Supervised Learning
â”‚  â”œâ”€ Classification
â”‚  â”‚  â”œâ”€ Generalized Linear Models
â”‚  â”‚  â”‚  â”œâ”€ [[Logistic Regression]]
â”‚  â”‚  â”‚  â”œâ”€ Probit Regression
â”‚  â”‚  â”‚  â””â”€ Multinomial Logistic Regression
â”‚  â”‚  â”œâ”€ [[Naive Bayes]]
â”‚  â”‚  â”‚  â”œâ”€ Gaussian Naive Bayes
â”‚  â”‚  â”‚  â”œâ”€ Multinomial Naive Bayes
â”‚  â”‚  â”‚  â”œâ”€ Bernoulli Naive Bayes
â”‚  â”‚  â”‚  â””â”€ Complement Naive Bayes
â”‚  â”‚  â”œâ”€ [[Decision Trees]]
â”‚  â”‚  â”‚  â”œâ”€ ID3
â”‚  â”‚  â”‚  â”œâ”€ C4.5
â”‚  â”‚  â”‚  â”œâ”€ CART
â”‚  â”‚  â”‚  â”œâ”€ CHAID
â”‚  â”‚  â”‚  â””â”€ Conditional Inference Trees
â”‚  â”‚  â”œâ”€ Rule-Based Classifiers
â”‚  â”‚  â”‚  â”œâ”€ OneR
â”‚  â”‚  â”‚  â”œâ”€ RIPPER
â”‚  â”‚  â”‚  â””â”€ PART
â”‚  â”‚  â”œâ”€ Ensemble Methods
â”‚  â”‚  â”‚  â”œâ”€ Bagging
â”‚  â”‚  â”‚  â”‚  â”œâ”€ [[Random Forest]]
â”‚  â”‚  â”‚  â”‚  â”œâ”€ Extra Trees
â”‚  â”‚  â”‚  â”‚  â””â”€ Bagged Decision Trees
â”‚  â”‚  â”‚  â”œâ”€ [[Boosting]]
â”‚  â”‚  â”‚  â”‚  â”œâ”€ AdaBoost
â”‚  â”‚  â”‚  â”‚  â”œâ”€ Gradient Boosting
â”‚  â”‚  â”‚  â”‚  â”‚  â”œâ”€ XGBoost
â”‚  â”‚  â”‚  â”‚  â”‚  â”œâ”€ LightGBM
â”‚  â”‚  â”‚  â”‚  â”‚  â””â”€ CatBoost
â”‚  â”‚  â”‚  â”‚  â””â”€ LogitBoost
â”‚  â”‚  â”‚  â”œâ”€ Stacking
â”‚  â”‚  â”‚  â”œâ”€ Voting
â”‚  â”‚  â”‚  â””â”€ Cascading
â”‚  â”‚  â”œâ”€ [[Support Vector Machines]] (SVM)
â”‚  â”‚  â”‚  â”œâ”€ Linear SVM
â”‚  â”‚  â”‚  â”œâ”€ Kernel SVM
â”‚  â”‚  â”‚  â”‚  â”œâ”€ Polynomial Kernel
â”‚  â”‚  â”‚  â”‚  â”œâ”€ RBF Kernel
â”‚  â”‚  â”‚  â”‚  â”œâ”€ Sigmoid Kernel
â”‚  â”‚  â”‚  â”‚  â””â”€ Custom Kernels
â”‚  â”‚  â”‚  â”œâ”€ One-Class SVM
â”‚  â”‚  â”‚  â””â”€ Multiclass SVM
â”‚  â”‚  â”‚     â”œâ”€ One-vs-One
â”‚  â”‚  â”‚     â””â”€ One-vs-Rest
â”‚  â”‚  â”œâ”€ K-Nearest Neighbors (KNN)
â”‚  â”‚  â”‚  â”œâ”€ Brute Force KNN
â”‚  â”‚  â”‚  â”œâ”€ KD-Trees
â”‚  â”‚  â”‚  â”œâ”€ Ball Trees
â”‚  â”‚  â”‚  â””â”€ Locality Sensitive Hashing (LSH)
â”‚  â”‚  â”œâ”€ Discriminant Analysis
â”‚  â”‚  â”‚  â”œâ”€ Linear Discriminant Analysis (LDA)
â”‚  â”‚  â”‚  â”œâ”€ Quadratic Discriminant Analysis (QDA)
â”‚  â”‚  â”‚  â””â”€ Regularized Discriminant Analysis (RDA)
â”‚  â”‚  â”œâ”€ [[Artificial neural network]]
â”‚  â”‚  â”‚  â”œâ”€ Multi-Layer Perceptron (MLP)
â”‚  â”‚  â”‚  â”œâ”€ [[Convolutional Neural Network]] (CNN)
â”‚  â”‚  â”‚  â”œâ”€ Capsule Networks
â”‚  â”‚  â”‚  â””â”€ [[Spiking Neural Network]] (SNN)
â”‚  â”‚  â””â”€ Other Classifiers
â”‚  â”‚     â”œâ”€ Bayesian Networks
â”‚  â”‚     â”œâ”€ Gaussian Processes
â”‚  â”‚     â””â”€ Relevance Vector Machines (RVM)
â”‚  â”‚
â”‚  â””â”€ Regression
â”‚     â”œâ”€ Linear Models
â”‚     â”‚  â”œâ”€ [[Linear Regression]]
â”‚     â”‚  â”œâ”€ [[Polynomial Regression]]
â”‚     â”‚  â”œâ”€ Stepwise Regression
â”‚     â”‚  â”œâ”€ LASSO (Least Absolute Shrinkage and Selection Operator)
â”‚     â”‚  â”œâ”€ Ridge Regression
â”‚     â”‚  â”œâ”€ Elastic Net
â”‚     â”‚  â””â”€ Least-Angle Regression (LARS)
â”‚     â”œâ”€ Regularization Methods
â”‚     â”‚  â”œâ”€ L1 Regularization (LASSO)
â”‚     â”‚  â”œâ”€ L2 Regularization (Ridge)
â”‚     â”‚  â””â”€ L1/L2 Regularization (Elastic Net)
â”‚     â”œâ”€ Decision Trees
â”‚     â”‚  â”œâ”€ Regression Trees
â”‚     â”‚  â””â”€ Model Trees
â”‚     â”œâ”€ [[Ensemble Methods]]
â”‚     â”‚  â”œâ”€ Random Forest
â”‚     â”‚  â”œâ”€ Gradient Boosting (e.g., XGBoost, LightGBM, CatBoost)
â”‚     â”‚  â”œâ”€ AdaBoost
â”‚     â”‚  â””â”€ Stacked Generalization (Stacking)
â”‚     â”œâ”€ Support Vector Regression (SVR)
â”‚     â”‚  â”œâ”€ Linear SVR
â”‚     â”‚  â”œâ”€ Non-Linear SVR
â”‚     â”‚  â””â”€ Kernels (e.g., RBF, Polynomial)
â”‚     â”œâ”€ Gaussian Process Regression (GPR)
â”‚     â”œâ”€ Isotonic Regression
â”‚     â”œâ”€ Quantile Regression
â”‚     â”œâ”€ Kriging (Spatial Interpolation)
â”‚     â””â”€ Neural Networks
â”‚        â”œâ”€ [[Multi-Layer Perceptron]] (MLP)
â”‚        â”œâ”€ [[Recurrent Neural Networks]] (RNN)
â”‚        â”‚  â”œâ”€ L[[ong Short-Term Memory]] (LSTM)
â”‚        â”‚  â””â”€ [[Gated Recurrent Unit]] (GRU)
â”‚        â””â”€ Convolutional Neural Networks (CNN)
â”‚
â”œâ”€ Unsupervised Learning
â”‚  â”œâ”€ [[Clustering]]
â”‚  â”‚  â”œâ”€ [[Partitioning Methods]]
â”‚  â”‚  â”‚  â”œâ”€ [[K-Means]]
â”‚  â”‚  â”‚  â”œâ”€ K-Medoids (PAM)
â”‚  â”‚  â”‚  â”œâ”€ Fuzzy C-Means
â”‚  â”‚  â”‚  â”œâ”€ Gaussian Mixture Models (GMM)
â”‚  â”‚  â”‚  â””â”€ Expectation-Maximization (EM)
â”‚  â”‚  â”œâ”€ [[Hierarchical Clustering]]
â”‚  â”‚  â”‚  â”œâ”€ Agglomerative Clustering
â”‚  â”‚  â”‚  â”‚  â”œâ”€ Single Linkage
â”‚  â”‚  â”‚  â”‚  â”œâ”€ Complete Linkage
â”‚  â”‚  â”‚  â”‚  â”œâ”€ Average Linkage
â”‚  â”‚  â”‚  â”‚  â””â”€ Ward's Method
â”‚  â”‚  â”‚  â””â”€ Divisive Clustering
â”‚  â”‚  â”‚     â”œâ”€ DIANA
â”‚  â”‚  â”‚     â””â”€ DISMEA
â”‚  â”‚  â”œâ”€ Density-Based Clustering
â”‚  â”‚  â”‚  â”œâ”€ DBSCAN
â”‚  â”‚  â”‚  â”œâ”€ OPTICS
â”‚  â”‚  â”‚  â”œâ”€ HDBSCAN
â”‚  â”‚  â”‚  â””â”€ DENCLUE
â”‚  â”‚  â”œâ”€ Grid-Based Clustering
â”‚  â”‚  â”‚  â”œâ”€ STING
â”‚  â”‚  â”‚  â”œâ”€ CLIQUE
â”‚  â”‚  â”‚  â””â”€ WaveCluster
â”‚  â”‚  â”œâ”€ Model-Based Clustering
â”‚  â”‚  â”‚  â”œâ”€ [[Self-Organizing Maps]] (SOM)
â”‚  â”‚  â”‚  â”œâ”€ Adaptive Resonance Theory (ART)
â”‚  â”‚  â”‚  â””â”€ Deep Embedded Clustering (DEC)
â”‚  â”‚  â””â”€ Other Clustering Methods
â”‚  â”‚     â”œâ”€ Spectral Clustering
â”‚  â”‚     â”œâ”€ Affinity Propagation
â”‚  â”‚     â”œâ”€ Mean Shift
â”‚  â”‚     â””â”€ BIRCH (Balanced Iterative Reducing and Clustering using Hierarchies)
â”‚  â”‚
â”‚  â”œâ”€ [[Dimensionality Reduction]]
â”‚  â”‚  â”œâ”€ Linear Methods
â”‚  â”‚  â”‚  â”œâ”€ Principal Component Analysis (PCA)
â”‚  â”‚  â”‚  â”œâ”€ Singular Value Decomposition (SVD)
â”‚  â”‚  â”‚  â”œâ”€ Non-Negative Matrix Factorization (NMF)
â”‚  â”‚  â”‚  â”œâ”€ Independent Component Analysis (ICA)
â”‚  â”‚  â”‚  â””â”€ Factor Analysis
â”‚  â”‚  â”œâ”€ Non-Linear Methods
â”‚  â”‚  â”‚  â”œâ”€ [[t-SNE]] (t-Distributed Stochastic Neighbor Embedding)
â”‚  â”‚  â”‚  â”œâ”€ [[UMAP]] (Uniform Manifold Approximation and Projection)
â”‚  â”‚  â”‚  â”œâ”€ Locally Linear Embedding (LLE)
â”‚  â”‚  â”‚  â”œâ”€ Isomap
â”‚  â”‚  â”‚  â”œâ”€ Laplacian Eigenmaps
â”‚  â”‚  â”‚  â”œâ”€ Diffusion Maps
â”‚  â”‚  â”‚  â”œâ”€ Kernel PCA
â”‚  â”‚  â”‚  â”œâ”€ [[Autoencoder]]
â”‚  â”‚  â”‚  â”‚  â”œâ”€ Vanilla Autoencoder
â”‚  â”‚  â”‚  â”‚  â”œâ”€ Denoising Autoencoder
â”‚  â”‚  â”‚  â”‚  â”œâ”€ [[Sparse Autoencoder]]
â”‚  â”‚  â”‚  â”‚  â””â”€ [[Variational Autoencoder]] (VAE)
â”‚  â”‚  â”‚  â””â”€ Self-Supervised Learning
â”‚  â”‚  â”‚     â”œâ”€ Contrastive Learning
â”‚  â”‚  â”‚     â””â”€ Clustering-Based Methods
â”‚  â”‚  â””â”€ [[Manifold Learning]]
â”‚  â”‚     â”œâ”€ Multidimensional Scaling (MDS)
â”‚  â”‚     â”œâ”€ Isomap
â”‚  â”‚     â”œâ”€ Locally Linear Embedding (LLE)
â”‚  â”‚     â”œâ”€ Laplacian Eigenmaps
â”‚  â”‚     â”œâ”€ Hessian Eigenmaps
â”‚  â”‚     â”œâ”€ Local Tangent Space Alignment (LTSA)
â”‚  â”‚     â””â”€ Diffusion Maps
â”‚  â”‚
â”‚  â””â”€ Association Rule Learning
â”‚     â”œâ”€ Apriori
â”‚     â”œâ”€ FP-Growth
â”‚     â”œâ”€ Eclat
â”‚     â””â”€ GUHA (General Unary Hypotheses Automaton)
â”‚
â”œâ”€ Semi-Supervised Learning
â”‚  â”œâ”€ Self-Training
â”‚  â”œâ”€ Co-Training
â”‚  â”œâ”€ Tri-Training
â”‚  â”œâ”€ Transductive SVM
â”‚  â”œâ”€ Graph-Based Methods
â”‚  â”‚  â”œâ”€ Label Propagation
â”‚  â”‚  â””â”€ Label Spreading
â”‚  â”œâ”€ Generative Models
â”‚  â”‚  â”œâ”€ Gaussian Mixture Models (GMM)
â”‚  â”‚  â””â”€ Variational Autoencoders (VAE)
â”‚  â””â”€ Low-Density Separation
â”‚     â”œâ”€ Transductive SVM
â”‚     â””â”€ S3VM (Semi-Supervised SVM)
â”‚
â”œâ”€ [[Reinforcement Learning]]
â”‚  â”œâ”€ [[Model-Free Methods]]
â”‚  â”‚  â”œâ”€ Value-Based Methods
â”‚  â”‚  â”‚  â”œâ”€ [[Q-Learning]]
â”‚  â”‚  â”‚  â”œâ”€ SARSA (State-Action-Reward-State-Action)
â”‚  â”‚  â”‚  â”œâ”€ Double Q-Learning
â”‚  â”‚  â”‚  â”œâ”€ Expected SARSA
â”‚  â”‚  â”‚  â””â”€ Deep Q-Networks (DQN)
â”‚  â”‚  â”‚     â”œâ”€ Double DQN
â”‚  â”‚  â”‚     â”œâ”€ Dueling DQN
â”‚  â”‚  â”‚     â”œâ”€ Prioritized Experience Replay (PER)
â”‚  â”‚  â”‚     â””â”€ Rainbow
â”‚  â”‚  â””â”€ Policy-Based Methods
â”‚  â”‚     â”œâ”€ Policy Gradients
â”‚  â”‚     â”‚  â”œâ”€ REINFORCE
â”‚  â”‚     â”‚  â”œâ”€ Advantage Actor-Critic (A2C)
â”‚  â”‚     â”‚  â”œâ”€ Asynchronous Advantage Actor-Critic (A3C)
â”‚  â”‚     â”‚  â”œâ”€ Proximal Policy Optimization (PPO)
â”‚  â”‚     â”‚  â””â”€ Trust Region Policy Optimization (TRPO)
â”‚  â”‚     â”œâ”€ Actor-Critic Methods
â”‚  â”‚     â”‚  â”œâ”€ Deterministic Policy Gradient (DPG)
â”‚  â”‚     â”‚  â”œâ”€ Deep Deterministic Policy Gradient (DDPG)
â”‚  â”‚     â”‚  â”œâ”€ Twin Delayed DDPG (TD3)
â”‚  â”‚     â”‚  â””â”€ Soft Actor-Critic (SAC)
â”‚  â”‚     â””â”€ Entropy-Based Methods
â”‚  â”‚        â”œâ”€ Soft Q-Learning
â”‚  â”‚        â””â”€ Soft Actor-Critic (SAC)
â”‚  â”‚
â”‚  â””â”€ Model-Based Methods
â”‚     â”œâ”€[[ Dynamic Programming]]
â”‚     â”‚  â”œâ”€ Value Iteration
â”‚     â”‚  â””â”€ Policy Iteration
â”‚     â”œâ”€ [[Monte Carlo Tree Search]] (MCTS)
â”‚     â”œâ”€ [[AlphaZero]]
â”‚     â”œâ”€ World Models
â”‚     â””â”€ Model-Based RL with Uncertainty
â”‚
â””â”€ [[Deep Learning]] ([[Artificial neural network]])
   â”œâ”€ [[Feedforward Neural Network]]
   â”‚  â”œâ”€ [[Multi-Layer Perceptron]] (MLP)
   â”‚  â”œâ”€ Extreme Learning Machines (ELM)
   â”‚  â”œâ”€ [[Echo State Network]] (ESN)
   â”‚  â”œâ”€ [[Liquid State Machine]](LSM)
   â”‚  â”œâ”€ [[Spiking Neural Network]] (SNN)
   â”‚  â”œâ”€ [[Autoencoder]]
   â”‚  â”‚  â”œâ”€ Vanilla Autoencoder
   â”‚  â”‚  â”œâ”€ Denoising Autoencoder
   â”‚  â”‚  â”œâ”€ Sparse Autoencoder
   â”‚  â”‚  â”œâ”€ Contractive Autoencoder
   â”‚  â”‚  â”œâ”€ [[Variational Autoencoder]] (VAE)
   â”‚  â”‚  â””â”€ Adversarial Autoencoder (AAE)
   â”‚  â””â”€ Deep Belief Networks (DBN)
   â”‚
   â”œâ”€ Convolutional Neural Networks (CNN)
   â”‚  â”œâ”€ LeNet
   â”‚  â”œâ”€ AlexNet
   â”‚  â”œâ”€ VGGNet
   â”‚  â”œâ”€ GoogLeNet (Inception)
   â”‚  â”œâ”€ ResNet
   â”‚  â”œâ”€ DenseNet
   â”‚  â”œâ”€ MobileNet
   â”‚  â”œâ”€ EfficientNet
   â”‚  â”œâ”€ Vision Transformers (ViT)
   â”‚  â”œâ”€ Spatial Transformer Networks (STN)
   â”‚  â”œâ”€ Deformable Convolutional Networks (DCN)
   â”‚  â”œâ”€ Capsule Networks
   â”‚  â””â”€ Attention-Based CNNs
   â”‚
   â”œâ”€ Recurrent Neural Networks (RNN)
   â”‚  â”œâ”€ Simple RNN
   â”‚  â”œâ”€ Long Short-Term Memory (LSTM)
   â”‚  â”œâ”€ Gated Recurrent Unit (GRU)
   â”‚  â”œâ”€ Bidirectional RNN
   â”‚  â”œâ”€ Attention Mechanisms
   â”‚  â”‚  â”œâ”€ Seq2Seq with Attention
   â”‚  â”‚  â”œâ”€ [[Transformer]]
   â”‚  â”‚  â”‚  â”œâ”€ BERT (Bidirectional Encoder Representations from Transformers)
   â”‚  â”‚  â”‚  â”œâ”€ GPT (Generative Pre-trained Transformer)
   â”‚  â”‚  â”‚  â”œâ”€ T5 (Text-to-Text Transfer Transformer)
   â”‚  â”‚  â”‚  â”œâ”€ XLNet
   â”‚  â”‚  â”‚  â”œâ”€ RoBERTa
   â”‚  â”‚  â”‚  â”œâ”€ ALBERT
   â”‚  â”‚  â”‚  â”œâ”€ ELECTRA
   â”‚  â”‚  â”‚  â””â”€ Reformer
   â”‚  â”‚  â””â”€ Pointer Networks
   â”‚  â”œâ”€ Memory Networks
   â”‚  â”œâ”€ [[Neural Turing Machine]](NTM)
   â”‚  â””â”€ [[Differentiable Neural Computer]] (DNC)
   â”‚
   â”œâ”€ Generative Models
   â”‚  â”œâ”€ [[Generative Adversarial Network]] (GAN)
   â”‚  â”‚  â”œâ”€ DCGAN (Deep Convolutional GAN)
   â”‚  â”‚  â”œâ”€ WGAN (Wasserstein GAN)
   â”‚  â”‚  â”œâ”€ CGAN (Conditional GAN)
   â”‚  â”‚  â”œâ”€ InfoGAN
   â”‚  â”‚  â”œâ”€ Pix2Pix
   â”‚  â”‚  â”œâ”€ CycleGAN
   â”‚  â”‚  â”œâ”€ StarGAN
   â”‚  â”‚  â”œâ”€ Progressive Growing of GANs (PGGAN)
   â”‚  â”‚  â”œâ”€ BigGAN
   â”‚  â”‚  â”œâ”€ StyleGAN
   â”‚  â”‚  â””â”€ Self-Attention GAN (SAGAN)
   â”‚  â”œâ”€ Variational Autoencoders (VAE)
   â”‚  â”‚  â”œâ”€ Conditional VAE (CVAE)
   â”‚  â”‚  â”œâ”€ Ladder VAE
   â”‚  â”‚  â”œâ”€ VQ-VAE (Vector Quantized VAE)
   â”‚  â”‚  â””â”€ Disentangled VAE (Î²-VAE, FactorVAE)
   â”‚  â”œâ”€ Flow-Based Models
   â”‚  â”‚  â”œâ”€ Normalizing Flows
   â”‚  â”‚  â”œâ”€ RealNVP
   â”‚  â”‚  â”œâ”€ Glow
   â”‚  â”‚  â””â”€ Masked Autoregressive Flow (MAF)
   â”‚  â”œâ”€ Energy-Based Models (EBM)
   â”‚  â””â”€ Autoregressive Models
   â”‚     â”œâ”€ PixelRNN
   â”‚     â”œâ”€ PixelCNN
   â”‚     â”œâ”€ WaveNet
   â”‚     â””â”€ Transformer-Based Models (e.g., GPT, CTRL)
   â”‚
   â”œâ”€ [[Graph Neural Network]] (GNN)
   â”‚  â”œâ”€ [[Graph Convolutional Network]] (GCN)
   â”‚  â”œâ”€ GraphSAGE
   â”‚  â”œâ”€ [[Graph Attention Network]] (GAT)
   â”‚  â”œâ”€ Graph Isomorphism Network (GIN)
   â”‚  â”œâ”€ Gated Graph Neural Networks (GGNN)
   â”‚  â”œâ”€ Graph Recurrent Networks (GRN)
   â”‚  â”œâ”€ Graph Autoencoders (GAE)
   â”‚  â””â”€ Graph Generative Models
   â”‚
   â””â”€ [[Deep Reinforcement Learning]]
      â”œâ”€ [[Deep Q-Networks]] (DQN)
      â”œâ”€ [[Policy Gradient Methods]]
      â”‚  â”œâ”€ TRPO (Trust Region Policy Optimization)
      â”‚  â”œâ”€ PPO (Proximal Policy Optimization)
      â”‚  â””â”€ DDPG (Deep Deterministic Policy Gradient)
      â”œâ”€ Actor-Critic Methods
      â”‚  â”œâ”€ A2C (Advantage Actor-Critic)
      â”‚  â”œâ”€ A3C (Asynchronous Advantage Actor-Critic)
      â”‚  â””â”€ ACER (Actor-Critic with Experience Replay)
      â”œâ”€ [[Distributional reinforcement learning]]
      â”‚  â”œâ”€ C51
      â”‚  â””â”€ QR-DQN (Quantile Regression DQN)
      â”œâ”€ [[Hierarchical reinforcement learning]]
      â”‚  â”œâ”€ Feudal Networks
      â”‚  â”œâ”€ Option-Critic
      â”‚  â””â”€ MAXQ
      â””â”€ Inverse Reinforcement Learning (IRL)
         â”œâ”€ Maximum Entropy IRL
         â”œâ”€ Generative Adversarial Imitation Learning (GAIL)
         â””â”€ Adversarial Inverse Reinforcement Learning (AIRL)
- Working with machine learning algorithms
1. Data Preprocessing:
   - Use NumPy and Pandas for data manipulation and preprocessing.
   - Scikit-learn provides various tools for data preprocessing, such as scaling, normalization, and encoding categorical variables.

2. Supervised Learning:
   - Scikit-learn offers implementations of many classic algorithms like linear regression, logistic regression, decision trees, SVMs, and naive Bayes.
   - For neural networks, you can use libraries like TensorFlow or PyTorch.
   - XGBoost, LightGBM, and CatBoost are popular libraries for gradient boosting.

3. Unsupervised Learning:
   - Scikit-learn provides implementations of clustering algorithms like K-means, DBSCAN, and hierarchical clustering.
   - For dimensionality reduction, you can use PCA, t-SNE, and UMAP from Scikit-learn.
   - Neural network-based techniques like autoencoders and GANs can be implemented using TensorFlow or PyTorch.

4. Semi-Supervised Learning:
   - Scikit-learn offers a few semi-supervised learning algorithms, such as label propagation and label spreading.
   - For more advanced techniques, you may need to implement them from scratch or look for specialized libraries.

5. Reinforcement Learning:
   - OpenAI Gym is a popular toolkit for developing and comparing reinforcement learning algorithms.
   - Stable Baselines and RLlib are libraries that provide implementations of various RL algorithms.
   - For deep reinforcement learning, you can use libraries like TensorFlow or PyTorch in combination with OpenAI Gym.

6. Deep Learning:
   - TensorFlow and PyTorch are the most widely used libraries for building and training deep neural networks.
   - Keras is a high-level neural networks API that can run on top of TensorFlow, CNTK, or Theano.
   - For specific architectures like CNNs, RNNs, and Transformers, these libraries offer pre-built layers and modules.
## Deep dives by AI 
- 
## AI 
- Machine learning, a branch of [[artificial intelligence]], focuses on the development of algorithms and [[statistics|statistical]] models that enable computers to perform tasks without explicit instructions, relying on patterns and inference instead. It encompasses a wide range of approaches and methodologies. Here's a comprehensive list of various branches and subfields within machine learning:
Here is a one-sentence explanation for each entry in your comprehensive list of machine learning branches and subfields:

### 1. Supervised Learning
   - **Regression (Linear, Polynomial, Logistic):** Involves predicting a continuous output variable based on one or more input features.
   - **Classification (Decision Trees, Support Vector Machines, k-Nearest Neighbors):** Focuses on categorizing data into predefined classes or groups.
   - **Ensemble Methods (Random Forests, Boosting, Bagging):** Combines multiple models to improve prediction accuracy or classification performance.
   - **Neural Networks and Deep Learning:** Complex structures modeled after the human brain that can learn from large amounts of data.
   - **Bayesian Networks:** Uses probabilistic models for a set of variables and their conditional dependencies.

### 2. Unsupervised Learning
   - **Clustering (k-Means, Hierarchical, DBSCAN):** Groups similar data points together without predefined labels.
   - **Dimensionality Reduction (PCA, t-SNE, LDA):** Reduces the number of random variables to consider, simplifying the dataset while retaining important information.
   - **Association Rule Learning (Apriori, Eclat):** Discovers interesting relations between variables in large databases.
   - **Anomaly Detection:** Identifies unusual patterns that do not conform to expected behavior.
   - **Autoencoders:** Neural networks used for unsupervised learning of efficient codings.

### 3. Semi-Supervised Learning
   - **Self-Training Models:** Use their own predictions to incrementally train on unlabeled data.
   - **Co-Training Approaches:** Train multiple learners on different views of the data and combine their predictions.
   - **Label Propagation:** Spreads labels through the dataset based on similarity and distance metrics.
   - **Generative Models:** Learns to generate new data samples that resemble the given training data.

### 4. Reinforcement Learning
   - **Q-Learning:** A value-based method for finding the optimal action-selection policy.
   - **Temporal Difference Methods:** Learn directly from raw experience without a model of the environmentâ€™s dynamics.
   - **Deep Reinforcement Learning:** Combines deep neural networks with reinforcement learning.
   - **Policy Optimization:** Focuses on finding the best policy directly, rather than evaluating a given policy.
   - **Multi-Armed Bandit Algorithms:** Solves problems where you have to choose between multiple options with uncertain outcomes.
   - **Monte Carlo Tree Search:** A heuristic search algorithm for decision-making processes, particularly in game playing.

### 5. Deep Learning
   - **Convolutional Neural Networks (CNNs):** Specialized for processing data with a grid-like topology, such as images.
   - **Recurrent Neural Networks (RNNs):** Designed for processing sequential data, such as time series or natural language.
   - **Long Short-Term Memory Networks (LSTMs):** An advanced type of RNN capable of learning long-term dependencies.
   - **Generative Adversarial Networks (GANs):** Consists of two neural networks contesting with each other to generate new, synthetic instances of data.
   - **Transformer Models:** Utilizes attention mechanisms to significantly improve the quality of results in NLP tasks.
   - **Deep Reinforcement Learning:** Integrates deep learning and reinforcement learning principles for complex problem-solving.
   - **Autoencoders and Variational Autoencoders:** Used for learning efficient codings of input data.

### 6. [[Natural Language Processing]] (NLP)
   - **Text Classification:** Assigns categories or labels to text based on its content.
   - **Sentiment Analysis:** Identifies and categorizes opinions expressed in text to determine the writer's attitude.
   - **Machine Translation:** Automatically translates text or speech from one language to another.
   - **Speech Recognition:** Converts spoken language into text.
   - **Language Generation:** Creates meaningful phrases, sentences, or entire articles.
   - **Named Entity Recognition:** Identifies and classifies key information (entities) in text.
   - **Topic Modeling:** Discovers abstract topics within a collection of documents.

### 7. Computer Vision
   - **Image Classification:** Assigns a label to an entire image or photograph.
   - **Object Detection:** Identifies and locates objects within an image.
   - **Image Segmentation:** Divides a digital image into multiple segments to simplify its representation.
   - **Face Recognition:** Identifies or verifies a person from a digital image or a video frame.
   - **Optical Character Recognition:** Converts different types of documents into editable and searchable data.
   - **Image Generation:** Creates new images, often from a given set of conditions or attributes.

### 8. Predictive Analytics
   - **Time Series Analysis:** Analyzes time-ordered sequence data to extract meaningful statistics and characteristics.
   - **Forecasting Models:** Predicts future values based on previously observed values

.
   - **Survival Analysis:** Analyzes and predicts the time until an event of interest occurs.
   - **Anomaly Detection in Time Series:** Identifies unusual patterns in time-ordered data that do not conform to expected behavior.

### 9. Recommender Systems
   - **Content-Based Filtering:** Recommends items similar to those a user likes, based on their previous actions or explicit feedback.
   - **Collaborative Filtering:** Makes automatic predictions about user interests by collecting preferences from many users.
   - **Hybrid Recommender Systems:** Combines content-based and collaborative filtering methods to improve recommendation accuracy.

### 10. Bayesian Learning
   - **Bayesian Networks:** Graphical models that represent probabilistic relationships among variables.
   - **Gaussian Processes:** A flexible approach to regression problems.
   - **Markov Chain Monte Carlo (MCMC) Methods:** A class of algorithms for sampling from probability distributions.
   - **Naive Bayes Classifiers:** A simple probabilistic classifier based on Bayes' theorem with strong independence assumptions.

### 11. Evolutionary Algorithms
   - **Genetic Algorithms:** Mimics the process of natural selection to solve optimization and search problems.
   - **Evolutionary Strategies:** Uses mechanisms inspired by biological evolution, such as reproduction, mutation, recombination, and selection.
   - **Genetic Programming:** Evolves computer programs to perform a specific task.

### 12. Feature Engineering and Selection
   - **Feature Extraction:** Reduces the number of resources required to describe a large set of data accurately.
   - **Feature Importance:** Identifies which features are most relevant to the outcome of a particular predictive model.
   - **Regularization Techniques (L1, L2):** Methods used to prevent overfitting by penalizing large coefficients in the model.

### 13. Interpretability and Explainability
   - **Model Interpretation Methods:** Techniques that make the outputs of machine learning models understandable to humans.
   - **Explainable AI (XAI) Techniques:** Strives to make the results of AI and machine learning algorithms transparent and understandable.
   - **Feature Importance Analysis:** Identifies and ranks the importance of different inputs to a model.

### 14. Ensemble Methods
   - **Boosting (AdaBoost, Gradient Boosting):** Combines weak learners to create a strong learner in a sequential manner.
   - **Bagging (Random Forest):** Uses bootstrapping to create an ensemble of models and then averages their predictions.
   - **Stacking:** Combines multiple classification or regression models via a meta-classifier or a meta-regressor.

### 15. Transfer Learning
   - **Domain Adaptation:** Adapts a model trained in one domain to be effective in a different domain.
   - **Fine-Tuning Pretrained Models:** Adjusts a pre-existing model to make it perform better in a specific task.
   - **Multi-Task Learning:** Improves learning efficiency and prediction accuracy for one task by using the knowledge gained while solving related tasks.

### 16. Distributed and Parallel Machine Learning
   - **Big Data Analytics:** Processes large volumes of data to extract useful information and insights.
   - **Scalable Machine Learning Algorithms:** Designed to handle increasing amounts of data or computation efficiently.
   - **Cloud-Based Machine Learning:** Utilizes cloud computing resources to build, train, and deploy machine learning models.

### 17. Optimization Techniques in Machine Learning
   - **Gradient Descent and Variants:** An iterative optimization algorithm used to minimize a function by moving in the direction of steepest descent.
   - **Stochastic Optimization:** Optimization methods that use randomness as part of the solution process.
   - **Convex Optimization:** A subfield of optimization that studies the problem of minimizing convex functions over convex sets.

### 18. Anomaly and Outlier Detection
   - **Statistical Methods for Anomaly Detection:** Identifies anomalies based on statistical models.
   - **Isolation Forest:** An algorithm to detect outliers that isolates anomalies instead of profiling normal data points.
   - **One-Class SVM:** A variant of SVM that is used for anomaly detection in an unsupervised manner.

### 19. Audio and Speech Processing
   - **Speech Recognition:** Transforms spoken language into text by computers.
   - **Music Classification:** Categorizes music into genres, moods, or other attributes using machine learning.
   - **Sound Generation:** Creates synthetic sounds or music.

### 20. Robotics and Control Systems
   - **Machine Learning in Robotics:** Applies machine learning techniques to enable robots to learn from and adapt to their environment.
   - **Control Systems Using Reinforcement Learning:** Uses reinforcement learning to optimize the performance of control systems.

Machine learning is a rapidly evolving field, continually incorporating new algorithms, techniques, and applications. Its versatility allows it to be applied across various domains, including finance, healthcare, education, transportation, and more, making it a pivotal technology in the modern world.
## Additional metadata 
-  #processed #processing #toprocess #important #short #long #casual #focus
- Unfinished: #metadata #tags