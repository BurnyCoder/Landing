## Tags
- Metadata: #topic 
- Part of: [[Machine learning]] [[Artificial Intelligence]] [[Capability]] [[Artificial intelligence safety]] 
- Related: 
- Includes:
- Additional: 
## Significance
- 
## Intuitive summaries
- 
## Definitions
- Study of taking a trained [[artificial neural network]], and analyzing the weights to reverse engineer the algorithms learned by the model.
## Technical summaries
-  
## Main resources 
- [Concrete Steps to Get Started in Transformer Mechanistic Interpretability — Neel Nanda](https://www.neelnanda.io/mechanistic-interpretability/getting-started)
	- <iframe src="https://www.neelnanda.io/mechanistic-interpretability/getting-started" allow="fullscreen" allowfullscreen="" style="height:100%;width:100%; aspect-ratio: 16 / 5; "></iframe>
## Landscapes
- [[Superposition]]
	- [[Cracking]]
- [[Grokking]]
	- [[Modular Addition]]
	- [[Induction heads]] [Induction heads - illustrated — LessWrong](https://www.lesswrong.com/posts/TvrfY4c9eaGLeyDkE/induction-heads-illustrated)
	- [[Representa]]
- [[Top down representation engineering]] - [Representation Engineering: A Top-Down Approach to AI Transparency](https://www.ai-transparency.org/)
## Contents
- 
## Deep dives
- 
## Brain storming
- 
## Additional resources  
- 
## Related
- 
## AI 
- 
## Additional metadata 
-  #processed #processing #toprocess #important #short #long #casual #focus
- Unfinished: #metadata #tags